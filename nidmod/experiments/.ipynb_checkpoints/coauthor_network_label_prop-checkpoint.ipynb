{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d363352",
   "metadata": {},
   "source": [
    "## Co-author Network Label Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877964d6",
   "metadata": {},
   "source": [
    "This experiment tests how different data integration setups can affect community label propagation in a co-author network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438eb56",
   "metadata": {},
   "source": [
    "We use the feature setup and network integrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261bf48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nidmod.datahandling.dataintegration import FeatureSetup, NetworkIntegrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d292e7",
   "metadata": {},
   "source": [
    "We have an adjacency matrix, an authors list, community labels for the nodes/authors, and noisy author names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a6e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from networkx.algorithms import node_classification\n",
    "\n",
    "adj = np.loadtxt('adjacency.txt')\n",
    "G = nx.from_numpy_matrix(adj)\n",
    "\n",
    "author_names = pd.read_csv('authors.txt', header = None)\n",
    "\n",
    "author_comms = pd.read_csv('commLabels.txt', sep = ' ')\n",
    "\n",
    "adjusted_names = pd.read_csv('authors_noisy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7f10e",
   "metadata": {},
   "source": [
    "We create dataframes and dictionaries with all the correct, non-noisy information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ed7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_authors = len(author_names)\n",
    "network0_names = author_names.rename(columns={0:'name'}, index=dict(zip(np.arange(num_authors), ['network0_' + str(x) for x in np.arange(num_authors)])))\n",
    "author_comms = author_comms.rename(index=dict(zip(np.arange(num_authors), ['network0_' + str(x) for x in np.arange(num_authors)])))\n",
    "author_comms_dict = author_comms.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad2c91f",
   "metadata": {},
   "source": [
    "We create a function that splits the true network randomly in two and then randomly relabels the nodes in the second network with the noisy author names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec58728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_networks():\n",
    "    G_0 = nx.Graph()\n",
    "    G_1 = nx.Graph()\n",
    "\n",
    "    G_0.add_nodes_from(list(G.nodes()))\n",
    "    G_1.add_nodes_from(list(G.nodes()))\n",
    "\n",
    "    # randomly dividing the edges between the two networks\n",
    "    for edge in list(G.edges()):\n",
    "\n",
    "        reassignment = np.random.randint(0, 2)\n",
    "        if reassignment == 0:\n",
    "            G_0.add_edge(*edge)\n",
    "        else:\n",
    "            G_1.add_edge(*edge)\n",
    "\n",
    "    G_0 = nx.relabel_nodes(G_0, dict(zip(list(G_0.nodes()), ['network0_' + str(x) for x in list(G_0.nodes())])))\n",
    "    G_1 = nx.relabel_nodes(G_1, dict(zip(list(G_1.nodes()), ['network1_' + str(x) for x in list(G_1.nodes())])))\n",
    "\n",
    "    network1_names = pd.DataFrame(index = ['network1_' + str(x) for x in np.arange(num_authors)])\n",
    "\n",
    "    # randomly relabelling the the nodes in the noisy network\n",
    "    names = []\n",
    "    for i in range(num_authors):\n",
    "        if np.random.randint(0,2) == 0:\n",
    "            names.append(adjusted_names.iloc[i].values[0])\n",
    "        else:\n",
    "            names.append(author_names.iloc[i].values[0])\n",
    "    network1_names['name'] = names\n",
    "    \n",
    "    return G_0, G_1, network1_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d0359f",
   "metadata": {},
   "source": [
    "We create a function that splits the networks and integrates them before running the label propagation. We can define which string similarity thresholds are tested and the number of simulations that are tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b60af001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_and_diffuse(thresholds, splits):\n",
    "    all_comm_prop = pd.DataFrame()\n",
    "    all_graph_prop = pd.DataFrame()\n",
    "\n",
    "    for num_split in range(splits):\n",
    "    \n",
    "        # we create the two networks with noisy author names\n",
    "        G_0, G_1, network1_names = create_split_networks()\n",
    "        \n",
    "        index_setup = {'Full': [[]]}\n",
    "        integrated_graphs = []\n",
    "\n",
    "        # for each string threshold, we perform integration\n",
    "        for string_threshold in thresholds:\n",
    "\n",
    "            compare_setup = {'String': [['name', 'name', 'levenshtein', string_threshold]]}\n",
    "\n",
    "            feature_setup = FeatureSetup(index_setup, compare_setup, network0_names, network1_names)\n",
    "            features = feature_setup.calculate_features()\n",
    "\n",
    "            pred_matches = features.loc[features[0] > 0]\n",
    "            pred_matches = pred_matches.index\n",
    "\n",
    "            network_integrator = NetworkIntegrator([G_0, G_1], pred_matches)\n",
    "            integrated_graphs.append(network_integrator.integrate_network('multigraph_walktrap_integration'))\n",
    "            \n",
    "        community_prop = pd.DataFrame(columns = ['comm_1', 'comm_2', 'nodes'])\n",
    "        graph_properties = pd.DataFrame(columns = ['graph', 'close_cent', 'bet_cent', 'har_cent'])\n",
    "        \n",
    "        # for each graph, we perform the label propagation\n",
    "        for graph in integrated_graphs:\n",
    "            \n",
    "            # the labels are available for the nodes network_0\n",
    "            nx.set_node_attributes(graph, author_comms_dict['SCORE'], \"label\")\n",
    "            \n",
    "            # we propagate with a harmonic function and check the number of nodes and proportion in each community\n",
    "            node_class = node_classification.harmonic_function(graph)\n",
    "            community_prop = community_prop.append({'comm_1': sum([x == 1 for x in node_class])/len(graph.nodes), \n",
    "                                                    'comm_2': 1 - sum([x == 1 for x in node_class])/len(graph.nodes),\n",
    "                                                    'nodes': len(graph.nodes())},\n",
    "                                                  ignore_index = True)\n",
    "            \n",
    "            # we calculate some graph properties\n",
    "            graph_properties = graph_properties.append({'graph': graph, 'deg_cent': np.mean(list(nx.degree_centrality(graph).values())),\n",
    "                                                       'close_cent': np.mean(list(nx.closeness_centrality(graph).values())),\n",
    "                                                       'bet_cent': np.mean(list(nx.betweenness_centrality(graph).values())),\n",
    "                                                       'har_cent': np.mean(list(nx.harmonic_centrality(graph).values()))}, ignore_index = True)\n",
    "\n",
    "        community_prop['threshold'] = thresholds\n",
    "        graph_properties['threshold'] = thresholds\n",
    "        all_comm_prop = pd.concat([all_comm_prop, community_prop])\n",
    "        all_graph_prop = pd.concat([all_graph_prop, graph_properties])\n",
    "\n",
    "        \n",
    "    return all_comm_prop, all_graph_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6470622c",
   "metadata": {},
   "source": [
    "We can execute the experiments with a number of thresholds and simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prop_results, graph_properties = integrate_and_diffuse(np.arange(0.5, 0.92, 0.02), 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
